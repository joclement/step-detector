{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.saved_model import loader\n",
    "\n",
    "import utils\n",
    "import data_mappers\n",
    "import nn_models\n",
    "tf.logging.set_verbosity(tf.logging.WARN)\n",
    "tf.__version__\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use(['seaborn-paper'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_recs = sorted(utils.enumerate_recording_paths('../dataset/raw/*record*'))\n",
    "our_recs += sorted(utils.enumerate_recording_paths('../dataset/raw/benni*/*record*'))\n",
    "kev_recs = sorted(utils.enumerate_recording_paths('/Users/pabloprietz/Dropbox/DCAITI_sharedfolder/Recordings/Kevin/rec*'))\n",
    "del kev_recs[:4]  # remove recordings with different sampling rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All cases\n",
    "\n",
    "## Export windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for single_rec in our_recs + kev_recs:\n",
    "    print(f'Exporting {single_rec}')\n",
    "    feeder = data_mappers.Window_Creator(rec_paths=[single_rec], train_test_split=1., window_size=120, subsample=1)\n",
    "    windows = feeder.accelerometer\n",
    "    labels = feeder.labels\n",
    "    np.savez_compressed(os.path.join(single_rec, 'window_export'), input=windows, labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_120_1 = 'saved_models/20-20_120_1_0.01_0.95/1519831256'\n",
    "cnn_120_1 = 'saved_models/no_maxpool_10-5--10-5_120_1_0.01_0.95/1519994594'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_recs = our_recs #+ kev_recs\n",
    "saved_model_dir = cnn_120_1\n",
    "tag_set = ['serve']\n",
    "\n",
    "with tf.Session(graph=tf.Graph()) as sess:\n",
    "    print(f'Loading model {saved_model_dir}')\n",
    "    loader.load(sess, tag_set, saved_model_dir)\n",
    "    graph_input = sess.graph.get_operation_by_name('accelerometer_input').values()[0]\n",
    "    graph_output = sess.graph.get_operation_by_name('softmax_tensor').values()[0]\n",
    "\n",
    "    for single_rec in all_recs:\n",
    "        print(f'Predicting {single_rec}')\n",
    "        data = np.load(os.path.join(single_rec, 'window_export.npz'))\n",
    "        prediction = sess.run(graph_output, feed_dict={graph_input: data['input']})\n",
    "        np.savez_compressed(os.path.join(single_rec, 'window_export.npz'), prediction=prediction, input=data['input'], labels=data['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize all predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_recs = our_recs + kev_recs\n",
    "cols = 2\n",
    "rows = len(all_recs) // cols + (0 if len(all_recs) % cols == 0 else 1)\n",
    "from string import ascii_uppercase\n",
    "\n",
    "for i, single_rec in enumerate(all_recs):\n",
    "    plt.figure(figsize=(10, 3))\n",
    "#     plt.subplot(rows, cols, i + 1)\n",
    "    data = np.load(os.path.join(single_rec, 'window_export.npz'))\n",
    "    windows = data['input']\n",
    "    labels = data['labels']\n",
    "    prediction = data['prediction']\n",
    "    \n",
    "    for d in [2]: # range(windows.shape[2]):\n",
    "        plt.plot(windows[:, windows.shape[1] // 2, d], label=('x', 'y', 'z')[d])\n",
    "\n",
    "#     for cls in range(prediction.shape[1]):\n",
    "#         plt.plot(prediction[:, cls], label=('not walking', 'walking')[cls])\n",
    "    plt.plot(np.argmax(prediction, axis=1), label='prediction')\n",
    "        \n",
    "    plt.plot(labels, label='labels')\n",
    "    plt.plot([0, 120], [1.1, 1.1], label='window width')\n",
    "    plt.legend()\n",
    "    plt.title(f'Recording {ascii_uppercase[i]}')\n",
    "    plt.xlabel('Window Index')\n",
    "    plt.ylabel('Normalized acceleration')\n",
    "    plt.ylim([-0.1, 1.2])\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'figures/all_windows_prediction_rec_{ascii_uppercase[i]}.png')\n",
    "    plt.show()\n",
    "#     plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edge cases\n",
    "Edge cases are windows whose ground truth sample labels have a majorty of less than 2/3, i.e. 0.33 < `raw_labels` < .67\n",
    "\n",
    "## Filter and save edge cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, single_rec in enumerate(our_recs + kev_recs):\n",
    "    feeder = data_mappers.Window_Creator(rec_paths=[single_rec], train_test_split=1., window_size=120, subsample=1)\n",
    "    raw_labels = feeder.raw_labels\n",
    "        \n",
    "    edge_cases = np.flatnonzero(np.logical_and(0.33 < raw_labels, raw_labels < 0.67))\n",
    "    edge_case_windows = feeder.accelerometer[edge_cases]\n",
    "    edge_case_labels = raw_labels[edge_cases]\n",
    "    print(f'Found {edge_cases.shape[0]} edge cases in {single_rec}')\n",
    "    np.savez_compressed(os.path.join(single_rec, 'edge_cases'), input=edge_case_windows, labels=edge_case_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict edge cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_recs = our_recs + kev_recs\n",
    "saved_model_dir = cnn_120_1\n",
    "tag_set = ['serve']\n",
    "\n",
    "with tf.Session(graph=tf.Graph()) as sess:\n",
    "    print(f'Loading model {saved_model_dir}')\n",
    "    loader.load(sess, tag_set, saved_model_dir)\n",
    "    graph_input = sess.graph.get_operation_by_name('accelerometer_input').values()[0]\n",
    "    graph_output = sess.graph.get_operation_by_name('softmax_tensor').values()[0]\n",
    "\n",
    "    for i, single_rec in enumerate(our_recs + kev_recs):\n",
    "        print(f'Predicting edge cases in {single_rec}')\n",
    "        data = np.load(os.path.join(single_rec, 'edge_cases.npz'))\n",
    "        prediction = sess.run(graph_output, feed_dict={graph_input: data['input']})\n",
    "        np.savez_compressed(os.path.join(single_rec, 'edge_cases.npz'), prediction=prediction, input=data['input'], labels=data['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize edge case predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, single_rec in enumerate(our_recs + kev_recs):\n",
    "    data = np.load(os.path.join(single_rec, 'edge_cases.npz'))\n",
    "    \n",
    "    plt.figure(figsize=(20, 3))\n",
    "    plt.plot([0, data['labels'].shape[0]], [.5, .5])\n",
    "    plt.plot(data['labels'], label='raw labels')\n",
    "    plt.plot(data['prediction'][:, 1], label='prediction')\n",
    "    plt.legend()\n",
    "    plt.ylim([-.1, 1.1])\n",
    "    plt.xlabel('Window Index')\n",
    "    plt.ylabel('Label Mean')\n",
    "    plt.title(f'Recording {ascii_uppercase[i]}')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(f'figures/low_label_conf_rec_{ascii_uppercase[i]}.png')\n",
    "    plt.show()\n",
    "#     plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfnightly",
   "language": "python",
   "name": "tfnightly"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
